{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etri-sw-soc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\etri-sw-soc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\etri-sw-soc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\etri-sw-soc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\etri-sw-soc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\etri-sw-soc\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense,Dropout\n",
    "from keras.models import Model\n",
    "from keras import regularizers,initializers\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/Users/etri-sw-soc/Desktop/temp/data.npy',allow_pickle=True) #numpy배열로 저장된 배열 가져오기\n",
    "label=np.load('/Users/etri-sw-soc/Desktop/temp/label.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34419, 1024)\n",
      "(14751, 1024)\n",
      "(34419, 10)\n",
      "[4800, 4800, 4800, 5568, 5250, 4752, 4800, 4800, 4800, 4800]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_nor=[]\n",
    "\n",
    "for i in data: #min-max 전처리\n",
    "    ii=[(float(i[j])) for j in range(1024)]\n",
    "    \n",
    "    temp2=[]\n",
    "    minv=min(ii)\n",
    "    maxv=max(ii)\n",
    "    maxmin=maxv-minv\n",
    "    for k in ii:\n",
    "        temp2.append((k-minv)/maxmin)\n",
    "    data_nor.append(temp2)   \n",
    "\n",
    "\n",
    "data_nor=np.array(data_nor)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_nor,label,test_size=0.3)\n",
    "y_test_num=y_test[:50] #autoencoder 성능 확인용 test 배열(그래프 print용)\n",
    "print( x_train.shape)\n",
    "print( x_test.shape)\n",
    "\n",
    "y_train=to_categorical(y_train,10) #라벨 형태 변환(십진수->010000형태)\n",
    "y_test=to_categorical(y_test,10)\n",
    "print(y_train.shape)\n",
    "\n",
    "a=[0,0,0,0,0,0,0,0,0,0] #한 클래스 당 데이터 수 확인\n",
    "for i in label:\n",
    "    a[i]+=1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation data 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8850, 1024) (5901, 1024)\n"
     ]
    }
   ],
   "source": [
    "#test data에서 train할때 사용할 validation용의 데이터 가져오기\n",
    "\n",
    "x_test, x_val, y_test, y_val=train_test_split(x_test,y_test,test_size=0.4)\n",
    "print(x_test.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder, decoder생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34419 samples, validate on 5901 samples\n",
      "Epoch 1/700\n",
      "34419/34419 [==============================] - 10s 288us/step - loss: 0.0601 - mean_squared_error: 0.0601 - acc: 6.9729e-04 - val_loss: 0.0462 - val_mean_squared_error: 0.0462 - val_acc: 0.0024\n",
      "Epoch 2/700\n",
      "34419/34419 [==============================] - 9s 271us/step - loss: 0.0380 - mean_squared_error: 0.0380 - acc: 0.0012 - val_loss: 0.0313 - val_mean_squared_error: 0.0313 - val_acc: 0.0019\n",
      "Epoch 3/700\n",
      "34419/34419 [==============================] - 11s 305us/step - loss: 0.0283 - mean_squared_error: 0.0283 - acc: 0.0012 - val_loss: 0.0286 - val_mean_squared_error: 0.0286 - val_acc: 0.0017\n",
      "Epoch 4/700\n",
      "34419/34419 [==============================] - 10s 303us/step - loss: 0.0259 - mean_squared_error: 0.0259 - acc: 0.0015 - val_loss: 0.0265 - val_mean_squared_error: 0.0265 - val_acc: 0.0012\n",
      "Epoch 5/700\n",
      "34419/34419 [==============================] - 10s 296us/step - loss: 0.0245 - mean_squared_error: 0.0245 - acc: 0.0022 - val_loss: 0.0250 - val_mean_squared_error: 0.0250 - val_acc: 0.0019\n",
      "Epoch 6/700\n",
      "34419/34419 [==============================] - 11s 308us/step - loss: 0.0241 - mean_squared_error: 0.0241 - acc: 0.0026 - val_loss: 0.0247 - val_mean_squared_error: 0.0247 - val_acc: 0.0019\n",
      "Epoch 7/700\n",
      "34419/34419 [==============================] - 11s 330us/step - loss: 0.0231 - mean_squared_error: 0.0231 - acc: 0.0029 - val_loss: 0.0228 - val_mean_squared_error: 0.0228 - val_acc: 0.0056\n",
      "Epoch 8/700\n",
      "34419/34419 [==============================] - 11s 317us/step - loss: 0.0219 - mean_squared_error: 0.0219 - acc: 0.0048 - val_loss: 0.0238 - val_mean_squared_error: 0.0238 - val_acc: 0.0064\n",
      "Epoch 9/700\n",
      "34419/34419 [==============================] - 10s 278us/step - loss: 0.0208 - mean_squared_error: 0.0208 - acc: 0.0056 - val_loss: 0.0214 - val_mean_squared_error: 0.0214 - val_acc: 0.0103\n",
      "Epoch 10/700\n",
      "34419/34419 [==============================] - 10s 283us/step - loss: 0.0198 - mean_squared_error: 0.0198 - acc: 0.0082 - val_loss: 0.0217 - val_mean_squared_error: 0.0217 - val_acc: 0.0119\n",
      "Epoch 11/700\n",
      "34419/34419 [==============================] - 11s 320us/step - loss: 0.0189 - mean_squared_error: 0.0189 - acc: 0.0084 - val_loss: 0.0201 - val_mean_squared_error: 0.0201 - val_acc: 0.0120\n",
      "Epoch 12/700\n",
      "34419/34419 [==============================] - 10s 277us/step - loss: 0.0181 - mean_squared_error: 0.0181 - acc: 0.0118 - val_loss: 0.0194 - val_mean_squared_error: 0.0194 - val_acc: 0.0125\n",
      "Epoch 13/700\n",
      "34419/34419 [==============================] - 12s 336us/step - loss: 0.0174 - mean_squared_error: 0.0174 - acc: 0.0123 - val_loss: 0.0189 - val_mean_squared_error: 0.0189 - val_acc: 0.0144\n",
      "Epoch 14/700\n",
      "34419/34419 [==============================] - 11s 311us/step - loss: 0.0168 - mean_squared_error: 0.0168 - acc: 0.0140 - val_loss: 0.0171 - val_mean_squared_error: 0.0171 - val_acc: 0.0176\n",
      "Epoch 15/700\n",
      "34419/34419 [==============================] - 10s 299us/step - loss: 0.0164 - mean_squared_error: 0.0164 - acc: 0.0168 - val_loss: 0.0188 - val_mean_squared_error: 0.0188 - val_acc: 0.0202\n",
      "Epoch 16/700\n",
      "34419/34419 [==============================] - 10s 282us/step - loss: 0.0160 - mean_squared_error: 0.0160 - acc: 0.0172 - val_loss: 0.0193 - val_mean_squared_error: 0.0193 - val_acc: 0.0215\n",
      "Epoch 17/700\n",
      "34419/34419 [==============================] - 10s 287us/step - loss: 0.0155 - mean_squared_error: 0.0155 - acc: 0.0189 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_acc: 0.0203\n",
      "Epoch 18/700\n",
      "34419/34419 [==============================] - 9s 266us/step - loss: 0.0153 - mean_squared_error: 0.0153 - acc: 0.0204 - val_loss: 0.0167 - val_mean_squared_error: 0.0167 - val_acc: 0.0266\n",
      "Epoch 19/700\n",
      "34419/34419 [==============================] - 9s 263us/step - loss: 0.0151 - mean_squared_error: 0.0151 - acc: 0.0216 - val_loss: 0.0169 - val_mean_squared_error: 0.0169 - val_acc: 0.0278\n",
      "Epoch 20/700\n",
      "34419/34419 [==============================] - 9s 258us/step - loss: 0.0150 - mean_squared_error: 0.0150 - acc: 0.0235 - val_loss: 0.0158 - val_mean_squared_error: 0.0158 - val_acc: 0.0308\n",
      "Epoch 21/700\n",
      "34419/34419 [==============================] - 9s 262us/step - loss: 0.0148 - mean_squared_error: 0.0148 - acc: 0.0249 - val_loss: 0.0158 - val_mean_squared_error: 0.0158 - val_acc: 0.0310\n",
      "Epoch 22/700\n",
      "34419/34419 [==============================] - 9s 259us/step - loss: 0.0147 - mean_squared_error: 0.0147 - acc: 0.0273 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_acc: 0.0329\n",
      "Epoch 23/700\n",
      "34419/34419 [==============================] - 9s 271us/step - loss: 0.0145 - mean_squared_error: 0.0145 - acc: 0.0269 - val_loss: 0.0173 - val_mean_squared_error: 0.0173 - val_acc: 0.0339\n",
      "Epoch 24/700\n",
      "34419/34419 [==============================] - 9s 273us/step - loss: 0.0144 - mean_squared_error: 0.0144 - acc: 0.0278 - val_loss: 0.0156 - val_mean_squared_error: 0.0156 - val_acc: 0.0354\n",
      "Epoch 25/700\n",
      "34419/34419 [==============================] - 9s 270us/step - loss: 0.0143 - mean_squared_error: 0.0143 - acc: 0.0300 - val_loss: 0.0165 - val_mean_squared_error: 0.0165 - val_acc: 0.0385\n",
      "Epoch 26/700\n",
      "34419/34419 [==============================] - 9s 262us/step - loss: 0.0142 - mean_squared_error: 0.0142 - acc: 0.0300 - val_loss: 0.0155 - val_mean_squared_error: 0.0155 - val_acc: 0.0403\n",
      "Epoch 27/700\n",
      "34419/34419 [==============================] - 9s 271us/step - loss: 0.0141 - mean_squared_error: 0.0141 - acc: 0.0329 - val_loss: 0.0157 - val_mean_squared_error: 0.0157 - val_acc: 0.0412\n",
      "Epoch 28/700\n",
      "34419/34419 [==============================] - 9s 266us/step - loss: 0.0139 - mean_squared_error: 0.0139 - acc: 0.0335 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_acc: 0.0408\n",
      "Epoch 29/700\n",
      "34419/34419 [==============================] - 9s 269us/step - loss: 0.0139 - mean_squared_error: 0.0139 - acc: 0.0340 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_acc: 0.0390\n",
      "Epoch 30/700\n",
      "34419/34419 [==============================] - 9s 273us/step - loss: 0.0138 - mean_squared_error: 0.0138 - acc: 0.0334 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_acc: 0.0446\n",
      "Epoch 31/700\n",
      "34419/34419 [==============================] - 9s 264us/step - loss: 0.0137 - mean_squared_error: 0.0137 - acc: 0.0368 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_acc: 0.0452\n",
      "Epoch 32/700\n",
      "34419/34419 [==============================] - 9s 262us/step - loss: 0.0137 - mean_squared_error: 0.0137 - acc: 0.0371 - val_loss: 0.0200 - val_mean_squared_error: 0.0200 - val_acc: 0.0412\n",
      "Epoch 33/700\n",
      "34419/34419 [==============================] - 9s 262us/step - loss: 0.0136 - mean_squared_error: 0.0136 - acc: 0.0365 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_acc: 0.0458\n",
      "Epoch 34/700\n",
      "34419/34419 [==============================] - 9s 276us/step - loss: 0.0134 - mean_squared_error: 0.0134 - acc: 0.0371 - val_loss: 0.0160 - val_mean_squared_error: 0.0160 - val_acc: 0.0488\n",
      "Epoch 35/700\n",
      "34419/34419 [==============================] - 9s 271us/step - loss: 0.0134 - mean_squared_error: 0.0134 - acc: 0.0379 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_acc: 0.0439\n",
      "Epoch 36/700\n",
      "34419/34419 [==============================] - 9s 263us/step - loss: 0.0134 - mean_squared_error: 0.0134 - acc: 0.0417 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_acc: 0.0536\n",
      "Epoch 37/700\n",
      "34419/34419 [==============================] - 9s 264us/step - loss: 0.0133 - mean_squared_error: 0.0133 - acc: 0.0412 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_acc: 0.0493\n",
      "Epoch 38/700\n",
      "34419/34419 [==============================] - 9s 267us/step - loss: 0.0132 - mean_squared_error: 0.0132 - acc: 0.0419 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_acc: 0.0537\n",
      "Epoch 39/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0132 - mean_squared_error: 0.0132 - acc: 0.0447 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_acc: 0.0478\n",
      "Epoch 40/700\n",
      "34419/34419 [==============================] - 9s 261us/step - loss: 0.0131 - mean_squared_error: 0.0131 - acc: 0.0420 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_acc: 0.0502\n",
      "Epoch 41/700\n",
      "34419/34419 [==============================] - 9s 266us/step - loss: 0.0131 - mean_squared_error: 0.0131 - acc: 0.0444 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_acc: 0.0544\n",
      "Epoch 42/700\n",
      "34419/34419 [==============================] - 9s 263us/step - loss: 0.0130 - mean_squared_error: 0.0130 - acc: 0.0476 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_acc: 0.0576\n",
      "Epoch 43/700\n",
      "34419/34419 [==============================] - 9s 257us/step - loss: 0.0130 - mean_squared_error: 0.0130 - acc: 0.0456 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_acc: 0.0561\n",
      "Epoch 44/700\n",
      "34419/34419 [==============================] - 9s 262us/step - loss: 0.0129 - mean_squared_error: 0.0129 - acc: 0.0478 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_acc: 0.0617\n",
      "Epoch 45/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0128 - mean_squared_error: 0.0128 - acc: 0.0476 - val_loss: 0.0160 - val_mean_squared_error: 0.0160 - val_acc: 0.0619\n",
      "Epoch 46/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0128 - mean_squared_error: 0.0128 - acc: 0.0490 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_acc: 0.0615\n",
      "Epoch 47/700\n",
      "34419/34419 [==============================] - 9s 261us/step - loss: 0.0128 - mean_squared_error: 0.0128 - acc: 0.0500 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_acc: 0.0659\n",
      "Epoch 48/700\n",
      "34419/34419 [==============================] - 9s 258us/step - loss: 0.0127 - mean_squared_error: 0.0127 - acc: 0.0503 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_acc: 0.0659\n",
      "Epoch 49/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0126 - mean_squared_error: 0.0126 - acc: 0.0534 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_acc: 0.0639\n",
      "Epoch 50/700\n",
      "34419/34419 [==============================] - 9s 257us/step - loss: 0.0126 - mean_squared_error: 0.0126 - acc: 0.0529 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_acc: 0.0696\n",
      "Epoch 51/700\n",
      "34419/34419 [==============================] - 9s 261us/step - loss: 0.0126 - mean_squared_error: 0.0126 - acc: 0.0526 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_acc: 0.0642\n",
      "Epoch 52/700\n",
      "34419/34419 [==============================] - 9s 261us/step - loss: 0.0126 - mean_squared_error: 0.0126 - acc: 0.0544 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_acc: 0.0683\n",
      "Epoch 53/700\n",
      "34419/34419 [==============================] - 9s 261us/step - loss: 0.0125 - mean_squared_error: 0.0125 - acc: 0.0561 - val_loss: 0.0135 - val_mean_squared_error: 0.0135 - val_acc: 0.0696\n",
      "Epoch 54/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0125 - mean_squared_error: 0.0125 - acc: 0.0534 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_acc: 0.0722\n",
      "Epoch 55/700\n",
      "34419/34419 [==============================] - 9s 259us/step - loss: 0.0124 - mean_squared_error: 0.0124 - acc: 0.0556 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_acc: 0.0708\n",
      "Epoch 56/700\n",
      "34419/34419 [==============================] - 9s 262us/step - loss: 0.0124 - mean_squared_error: 0.0124 - acc: 0.0566 - val_loss: 0.0134 - val_mean_squared_error: 0.0134 - val_acc: 0.0707\n",
      "Epoch 57/700\n",
      "34419/34419 [==============================] - 9s 259us/step - loss: 0.0123 - mean_squared_error: 0.0123 - acc: 0.0551 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_acc: 0.0786\n",
      "Epoch 58/700\n",
      "34419/34419 [==============================] - 9s 264us/step - loss: 0.0123 - mean_squared_error: 0.0123 - acc: 0.0565 - val_loss: 0.0132 - val_mean_squared_error: 0.0132 - val_acc: 0.0698\n",
      "Epoch 59/700\n",
      "34419/34419 [==============================] - 9s 259us/step - loss: 0.0123 - mean_squared_error: 0.0123 - acc: 0.0588 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_acc: 0.0712\n",
      "Epoch 60/700\n",
      "34419/34419 [==============================] - 9s 263us/step - loss: 0.0122 - mean_squared_error: 0.0122 - acc: 0.0581 - val_loss: 0.0124 - val_mean_squared_error: 0.0124 - val_acc: 0.0773\n",
      "Epoch 61/700\n",
      "34419/34419 [==============================] - 9s 259us/step - loss: 0.0122 - mean_squared_error: 0.0122 - acc: 0.0597 - val_loss: 0.0135 - val_mean_squared_error: 0.0135 - val_acc: 0.0798\n",
      "Epoch 62/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0122 - mean_squared_error: 0.0122 - acc: 0.0589 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_acc: 0.0771\n",
      "Epoch 63/700\n",
      "34419/34419 [==============================] - 9s 266us/step - loss: 0.0121 - mean_squared_error: 0.0121 - acc: 0.0617 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_acc: 0.0805\n",
      "Epoch 64/700\n",
      "34419/34419 [==============================] - 9s 258us/step - loss: 0.0121 - mean_squared_error: 0.0121 - acc: 0.0620 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_acc: 0.0851\n",
      "Epoch 65/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0120 - mean_squared_error: 0.0120 - acc: 0.0628 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_acc: 0.0793\n",
      "Epoch 66/700\n",
      "34419/34419 [==============================] - 9s 258us/step - loss: 0.0120 - mean_squared_error: 0.0120 - acc: 0.0626 - val_loss: 0.0130 - val_mean_squared_error: 0.0130 - val_acc: 0.0825\n",
      "Epoch 67/700\n",
      "34419/34419 [==============================] - 9s 261us/step - loss: 0.0120 - mean_squared_error: 0.0120 - acc: 0.0631 - val_loss: 0.0127 - val_mean_squared_error: 0.0127 - val_acc: 0.0805\n",
      "Epoch 68/700\n",
      "34419/34419 [==============================] - 9s 257us/step - loss: 0.0120 - mean_squared_error: 0.0120 - acc: 0.0625 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_acc: 0.0803\n",
      "Epoch 69/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0119 - mean_squared_error: 0.0119 - acc: 0.0646 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_acc: 0.0786\n",
      "Epoch 70/700\n",
      "34419/34419 [==============================] - 9s 272us/step - loss: 0.0119 - mean_squared_error: 0.0119 - acc: 0.0632 - val_loss: 0.0128 - val_mean_squared_error: 0.0128 - val_acc: 0.0827\n",
      "Epoch 71/700\n",
      "34419/34419 [==============================] - 9s 266us/step - loss: 0.0119 - mean_squared_error: 0.0119 - acc: 0.0645 - val_loss: 0.0130 - val_mean_squared_error: 0.0130 - val_acc: 0.0783\n",
      "Epoch 72/700\n",
      "34419/34419 [==============================] - 9s 267us/step - loss: 0.0119 - mean_squared_error: 0.0119 - acc: 0.0651 - val_loss: 0.0122 - val_mean_squared_error: 0.0122 - val_acc: 0.0813\n",
      "Epoch 73/700\n",
      "34419/34419 [==============================] - 9s 260us/step - loss: 0.0118 - mean_squared_error: 0.0118 - acc: 0.0642 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_acc: 0.0822\n",
      "Epoch 74/700\n",
      "34419/34419 [==============================] - 9s 262us/step - loss: 0.0118 - mean_squared_error: 0.0118 - acc: 0.0641 - val_loss: 0.0130 - val_mean_squared_error: 0.0130 - val_acc: 0.0868\n",
      "Epoch 75/700\n",
      "34419/34419 [==============================] - 9s 271us/step - loss: 0.0118 - mean_squared_error: 0.0118 - acc: 0.0643 - val_loss: 0.0136 - val_mean_squared_error: 0.0136 - val_acc: 0.0844\n",
      "Epoch 76/700\n",
      "34419/34419 [==============================] - 10s 296us/step - loss: 0.0117 - mean_squared_error: 0.0117 - acc: 0.0673 - val_loss: 0.0129 - val_mean_squared_error: 0.0129 - val_acc: 0.0854\n",
      "Epoch 77/700\n",
      "34419/34419 [==============================] - 11s 311us/step - loss: 0.0117 - mean_squared_error: 0.0117 - acc: 0.0678 - val_loss: 0.0134 - val_mean_squared_error: 0.0134 - val_acc: 0.0912\n",
      "Epoch 78/700\n",
      "34419/34419 [==============================] - 10s 300us/step - loss: 0.0117 - mean_squared_error: 0.0117 - acc: 0.0682 - val_loss: 0.0130 - val_mean_squared_error: 0.0130 - val_acc: 0.0791\n",
      "Epoch 79/700\n",
      "34419/34419 [==============================] - 11s 306us/step - loss: 0.0117 - mean_squared_error: 0.0117 - acc: 0.0691 - val_loss: 0.0130 - val_mean_squared_error: 0.0130 - val_acc: 0.0874\n",
      "Epoch 80/700\n",
      "34419/34419 [==============================] - 10s 279us/step - loss: 0.0117 - mean_squared_error: 0.0117 - acc: 0.0691 - val_loss: 0.0126 - val_mean_squared_error: 0.0126 - val_acc: 0.0844\n",
      "Epoch 81/700\n",
      "34419/34419 [==============================] - 9s 261us/step - loss: 0.0116 - mean_squared_error: 0.0116 - acc: 0.0698 - val_loss: 0.0129 - val_mean_squared_error: 0.0129 - val_acc: 0.0898\n",
      "Epoch 82/700\n",
      "34419/34419 [==============================] - 10s 281us/step - loss: 0.0116 - mean_squared_error: 0.0116 - acc: 0.0666 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_acc: 0.0873\n",
      "Epoch 83/700\n",
      "11200/34419 [========>.....................] - ETA: 7s - loss: 0.0116 - mean_squared_error: 0.0116 - acc: 0.0670"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-92dc08fa1e0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#optimizer=Adam(lr=0.002)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mauto_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m350\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#autoencoder 생성\n",
    "l2_regularizer =regularizers.l2(0.00001)    #tf.contrib.layers.l2_regularizer(scale=0.0001)\n",
    "\n",
    "input_dim=1024\n",
    "encoding_dim =512 #256의 경우 너무 많이 압축되어 autoencoder의 성능이 떨어짐.\n",
    "dropout_rate=0.1\n",
    "\n",
    "input_ = Input(shape=(input_dim,))\n",
    "encoded = Dense(input_dim, activation=tf.nn.relu)(input_) #12_regularizer을 안쓰는 것이 성능이 더 좋은 경우도 O->제거\n",
    "encoded=Dropout(dropout_rate)(encoded)\n",
    "encoded=Dense(int(encoding_dim*1.5),activation=tf.nn.relu)(encoded)\n",
    "encoded=Dropout(dropout_rate)(encoded)\n",
    "decoded=Dense(encoding_dim,activation=tf.nn.relu)(encoded)\n",
    "decoded=Dense(int(encoding_dim*1.5),activation=tf.nn.relu)(decoded)\n",
    "decoded = Dense(input_dim, activation=tf.nn.relu)(decoded)\n",
    "\n",
    "encoder=Model(input_,encoded)\n",
    "\n",
    "autoencoder= Model(input_, decoded)\n",
    "\n",
    "encoded_input=Input(shape=(encoding_dim,))\n",
    "decoder_layer2=autoencoder.layers[-2]\n",
    "decoder_layer1=autoencoder.layers[-1]\n",
    "decoder=Model(encoded_input, decoder_layer1(decoder_layer2((encoded_input))))\n",
    "\n",
    "#autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse'])\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['mse','accuracy']) #optimizer=Adam(lr=0.002)\n",
    "auto_train=autoencoder.fit(x_train, x_train, epochs=700, batch_size=350,shuffle=True,validation_data=(x_val,x_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder, decoder plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "\n",
    "def plotting(startpoint,n): #autoencoder성능 확인용 함수 (기존 데이터와 재생성 데이터 plot)\n",
    "    print('실제 라벨 : ',y_test_num[startpoint:startpoint+n]) #정답 라벨 프린트\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    for i in range( n):\n",
    "        # original data\n",
    "        ax = plt.subplot(2, n, i + 1) \n",
    "        plt.plot(x_test[startpoint+i])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.plot(decoded_result[startpoint+i])\n",
    "        #plt.plot(x_test_noise[startpoint+i])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "encoded_result=encoder.predict(x_test[:30]) #autoencoder 성능 확인용 print\n",
    "decoded_result=decoder.predict(encoded_result)\n",
    "\n",
    "plotting(0,10) #test 데이터에 autoencoder적용 결과 plot(test데이터의 0~10번째 데이터)\n",
    "plotting(10,10) #test데이터의 10~20번째 데이터 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Layer추가, Fine tuning\n",
    "dropout_rate_=0.2 #얼마나 dropout할지\n",
    "\n",
    "model=Sequential()\n",
    "count=0\n",
    "for layer in encoder.layers: #model에 encoder부분 추가하기\n",
    "    model.add(layer)\n",
    "        \n",
    "for layer in model.layers: #encoder부분은 더이상 학습X\n",
    "    layer.trainable=False\n",
    "     \n",
    "model.add(Dense(1024, activation='relu'))  \n",
    "model.add(Dropout(dropout_rate_))\n",
    "model.add(Dense(1024, activation='relu'))  \n",
    "model.add(Dropout(dropout_rate_))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34419 samples, validate on 5901 samples\n",
      "Epoch 1/300\n",
      " - 8s - loss: 1.8046 - acc: 0.3346 - val_loss: 1.5550 - val_acc: 0.4276\n",
      "Epoch 2/300\n",
      " - 7s - loss: 1.5072 - acc: 0.4467 - val_loss: 1.4022 - val_acc: 0.4875\n",
      "Epoch 3/300\n",
      " - 7s - loss: 1.3581 - acc: 0.4978 - val_loss: 1.2421 - val_acc: 0.5477\n",
      "Epoch 4/300\n",
      " - 7s - loss: 1.2436 - acc: 0.5446 - val_loss: 1.1752 - val_acc: 0.5723\n",
      "Epoch 5/300\n",
      " - 7s - loss: 1.1461 - acc: 0.5792 - val_loss: 1.1017 - val_acc: 0.5994\n",
      "Epoch 6/300\n",
      " - 7s - loss: 1.0588 - acc: 0.6113 - val_loss: 1.0379 - val_acc: 0.6219\n",
      "Epoch 7/300\n",
      " - 7s - loss: 1.0004 - acc: 0.6393 - val_loss: 0.9691 - val_acc: 0.6487\n",
      "Epoch 8/300\n",
      " - 7s - loss: 0.9378 - acc: 0.6593 - val_loss: 0.9424 - val_acc: 0.6587\n",
      "Epoch 9/300\n",
      " - 7s - loss: 0.8768 - acc: 0.6853 - val_loss: 0.9274 - val_acc: 0.6682\n",
      "Epoch 10/300\n",
      " - 7s - loss: 0.8355 - acc: 0.6997 - val_loss: 0.8667 - val_acc: 0.6904\n",
      "Epoch 11/300\n",
      " - 7s - loss: 0.7978 - acc: 0.7114 - val_loss: 0.8994 - val_acc: 0.6723\n",
      "Epoch 12/300\n",
      " - 7s - loss: 0.7538 - acc: 0.7290 - val_loss: 0.8383 - val_acc: 0.6978\n",
      "Epoch 13/300\n",
      " - 7s - loss: 0.7207 - acc: 0.7394 - val_loss: 0.8566 - val_acc: 0.6895\n",
      "Epoch 14/300\n",
      " - 8s - loss: 0.6974 - acc: 0.7480 - val_loss: 0.8612 - val_acc: 0.6853\n",
      "Epoch 15/300\n",
      " - 7s - loss: 0.6670 - acc: 0.7600 - val_loss: 0.7990 - val_acc: 0.7126\n",
      "Epoch 16/300\n",
      " - 7s - loss: 0.6374 - acc: 0.7724 - val_loss: 0.8267 - val_acc: 0.7094\n",
      "Epoch 17/300\n",
      " - 7s - loss: 0.6125 - acc: 0.7798 - val_loss: 0.8080 - val_acc: 0.7145\n",
      "Epoch 18/300\n",
      " - 7s - loss: 0.6008 - acc: 0.7851 - val_loss: 0.7939 - val_acc: 0.7258\n",
      "Epoch 19/300\n",
      " - 7s - loss: 0.5918 - acc: 0.7884 - val_loss: 0.7557 - val_acc: 0.7299\n",
      "Epoch 20/300\n",
      " - 7s - loss: 0.5687 - acc: 0.7972 - val_loss: 0.7956 - val_acc: 0.7192\n",
      "Epoch 21/300\n",
      " - 7s - loss: 0.5470 - acc: 0.8036 - val_loss: 0.7626 - val_acc: 0.7236\n",
      "Epoch 22/300\n",
      " - 7s - loss: 0.5321 - acc: 0.8109 - val_loss: 0.7743 - val_acc: 0.7284\n",
      "Epoch 23/300\n",
      " - 7s - loss: 0.5189 - acc: 0.8151 - val_loss: 0.7799 - val_acc: 0.7333\n",
      "Epoch 24/300\n",
      " - 7s - loss: 0.5042 - acc: 0.8215 - val_loss: 0.7879 - val_acc: 0.7290\n",
      "Epoch 25/300\n",
      " - 7s - loss: 0.5016 - acc: 0.8209 - val_loss: 0.7807 - val_acc: 0.7304\n",
      "Epoch 26/300\n",
      " - 7s - loss: 0.4940 - acc: 0.8239 - val_loss: 0.7861 - val_acc: 0.7280\n",
      "Epoch 27/300\n",
      " - 7s - loss: 0.4748 - acc: 0.8308 - val_loss: 0.7805 - val_acc: 0.7336\n",
      "Epoch 28/300\n",
      " - 7s - loss: 0.4616 - acc: 0.8349 - val_loss: 0.7899 - val_acc: 0.7311\n",
      "Epoch 29/300\n",
      " - 7s - loss: 0.4582 - acc: 0.8357 - val_loss: 0.7499 - val_acc: 0.7416\n",
      "Epoch 30/300\n",
      " - 7s - loss: 0.4379 - acc: 0.8444 - val_loss: 0.7339 - val_acc: 0.7475\n",
      "Epoch 31/300\n",
      " - 7s - loss: 0.4282 - acc: 0.8506 - val_loss: 0.7745 - val_acc: 0.7411\n",
      "Epoch 32/300\n",
      " - 7s - loss: 0.4279 - acc: 0.8492 - val_loss: 0.7826 - val_acc: 0.7397\n",
      "Epoch 33/300\n",
      " - 7s - loss: 0.4100 - acc: 0.8513 - val_loss: 0.7667 - val_acc: 0.7465\n",
      "Epoch 34/300\n",
      " - 8s - loss: 0.4149 - acc: 0.8521 - val_loss: 0.7470 - val_acc: 0.7502\n",
      "Epoch 35/300\n",
      " - 8s - loss: 0.4039 - acc: 0.8568 - val_loss: 0.7397 - val_acc: 0.7519\n",
      "Epoch 36/300\n",
      " - 7s - loss: 0.3917 - acc: 0.8602 - val_loss: 0.7463 - val_acc: 0.7526\n",
      "Epoch 37/300\n",
      " - 7s - loss: 0.3878 - acc: 0.8625 - val_loss: 0.7880 - val_acc: 0.7436\n",
      "Epoch 38/300\n",
      " - 8s - loss: 0.3835 - acc: 0.8655 - val_loss: 0.7815 - val_acc: 0.7494\n",
      "Epoch 39/300\n",
      " - 7s - loss: 0.3748 - acc: 0.8686 - val_loss: 0.7715 - val_acc: 0.7521\n",
      "Epoch 40/300\n",
      " - 6s - loss: 0.3754 - acc: 0.8682 - val_loss: 0.7747 - val_acc: 0.7472\n",
      "Epoch 41/300\n",
      " - 8s - loss: 0.3703 - acc: 0.8700 - val_loss: 0.7822 - val_acc: 0.7512\n",
      "Epoch 42/300\n",
      " - 8s - loss: 0.3616 - acc: 0.8720 - val_loss: 0.7880 - val_acc: 0.7470\n",
      "Epoch 43/300\n",
      " - 7s - loss: 0.3683 - acc: 0.8705 - val_loss: 0.7732 - val_acc: 0.7456\n",
      "Epoch 44/300\n",
      " - 6s - loss: 0.3482 - acc: 0.8777 - val_loss: 0.7733 - val_acc: 0.7539\n",
      "Epoch 45/300\n",
      " - 7s - loss: 0.3521 - acc: 0.8757 - val_loss: 0.7593 - val_acc: 0.7531\n",
      "Epoch 46/300\n",
      " - 7s - loss: 0.3443 - acc: 0.8786 - val_loss: 0.7465 - val_acc: 0.7534\n",
      "Epoch 47/300\n",
      " - 7s - loss: 0.3425 - acc: 0.8814 - val_loss: 0.7710 - val_acc: 0.7497\n",
      "Epoch 48/300\n",
      " - 8s - loss: 0.3309 - acc: 0.8842 - val_loss: 0.7580 - val_acc: 0.7587\n",
      "Epoch 49/300\n",
      " - 7s - loss: 0.3333 - acc: 0.8830 - val_loss: 0.7517 - val_acc: 0.7570\n",
      "Epoch 50/300\n",
      " - 7s - loss: 0.3256 - acc: 0.8857 - val_loss: 0.7626 - val_acc: 0.7622\n",
      "Epoch 51/300\n",
      " - 7s - loss: 0.3241 - acc: 0.8861 - val_loss: 0.7484 - val_acc: 0.7624\n",
      "Epoch 52/300\n",
      " - 8s - loss: 0.3204 - acc: 0.8854 - val_loss: 0.7538 - val_acc: 0.7573\n",
      "Epoch 53/300\n",
      " - 7s - loss: 0.3057 - acc: 0.8927 - val_loss: 0.7595 - val_acc: 0.7583\n",
      "Epoch 54/300\n",
      " - 8s - loss: 0.3096 - acc: 0.8926 - val_loss: 0.7773 - val_acc: 0.7543\n",
      "Epoch 55/300\n",
      " - 8s - loss: 0.3111 - acc: 0.8890 - val_loss: 0.7234 - val_acc: 0.7624\n",
      "Epoch 56/300\n",
      " - 8s - loss: 0.3058 - acc: 0.8931 - val_loss: 0.7470 - val_acc: 0.7614\n",
      "Epoch 57/300\n",
      " - 8s - loss: 0.3045 - acc: 0.8935 - val_loss: 0.7337 - val_acc: 0.7677\n",
      "Epoch 58/300\n",
      " - 8s - loss: 0.3061 - acc: 0.8930 - val_loss: 0.7998 - val_acc: 0.7555\n",
      "Epoch 59/300\n",
      " - 8s - loss: 0.3052 - acc: 0.8960 - val_loss: 0.7454 - val_acc: 0.7677\n",
      "Epoch 60/300\n",
      " - 8s - loss: 0.2925 - acc: 0.8981 - val_loss: 0.7758 - val_acc: 0.7561\n",
      "Epoch 61/300\n",
      " - 8s - loss: 0.2897 - acc: 0.9000 - val_loss: 0.7435 - val_acc: 0.7683\n",
      "Epoch 62/300\n",
      " - 7s - loss: 0.2906 - acc: 0.8985 - val_loss: 0.7642 - val_acc: 0.7556\n",
      "Epoch 63/300\n",
      " - 8s - loss: 0.2826 - acc: 0.9035 - val_loss: 0.7282 - val_acc: 0.7705\n",
      "Epoch 64/300\n",
      " - 7s - loss: 0.2830 - acc: 0.9010 - val_loss: 0.7534 - val_acc: 0.7702\n",
      "Epoch 65/300\n",
      " - 7s - loss: 0.2791 - acc: 0.9025 - val_loss: 0.7569 - val_acc: 0.7597\n",
      "Epoch 66/300\n",
      " - 7s - loss: 0.2738 - acc: 0.9061 - val_loss: 0.7924 - val_acc: 0.7604\n",
      "Epoch 67/300\n",
      " - 7s - loss: 0.2832 - acc: 0.9011 - val_loss: 0.7554 - val_acc: 0.7614\n",
      "Epoch 68/300\n",
      " - 7s - loss: 0.2782 - acc: 0.9034 - val_loss: 0.7729 - val_acc: 0.7699\n",
      "Epoch 69/300\n",
      " - 7s - loss: 0.2723 - acc: 0.9049 - val_loss: 0.8161 - val_acc: 0.7590\n",
      "Epoch 70/300\n",
      " - 8s - loss: 0.2740 - acc: 0.9060 - val_loss: 0.7416 - val_acc: 0.7689\n",
      "Epoch 71/300\n",
      " - 7s - loss: 0.2696 - acc: 0.9073 - val_loss: 0.7467 - val_acc: 0.7700\n",
      "Epoch 72/300\n",
      " - 7s - loss: 0.2721 - acc: 0.9060 - val_loss: 0.7736 - val_acc: 0.7622\n",
      "Epoch 73/300\n",
      " - 8s - loss: 0.2631 - acc: 0.9096 - val_loss: 0.7684 - val_acc: 0.7641\n",
      "Epoch 74/300\n",
      " - 7s - loss: 0.2600 - acc: 0.9104 - val_loss: 0.7712 - val_acc: 0.7685\n",
      "Epoch 75/300\n",
      " - 7s - loss: 0.2616 - acc: 0.9100 - val_loss: 0.7785 - val_acc: 0.7604\n",
      "Epoch 76/300\n",
      " - 7s - loss: 0.2621 - acc: 0.9099 - val_loss: 0.7536 - val_acc: 0.7695\n",
      "Epoch 77/300\n",
      " - 7s - loss: 0.2569 - acc: 0.9116 - val_loss: 0.7321 - val_acc: 0.7777\n",
      "Epoch 78/300\n",
      " - 7s - loss: 0.2529 - acc: 0.9121 - val_loss: 0.7586 - val_acc: 0.7675\n",
      "Epoch 79/300\n",
      " - 7s - loss: 0.2491 - acc: 0.9147 - val_loss: 0.7676 - val_acc: 0.7734\n",
      "Epoch 80/300\n",
      " - 7s - loss: 0.2567 - acc: 0.9121 - val_loss: 0.7609 - val_acc: 0.7678\n",
      "Epoch 81/300\n",
      " - 7s - loss: 0.2483 - acc: 0.9130 - val_loss: 0.7484 - val_acc: 0.7699\n",
      "Epoch 82/300\n",
      " - 7s - loss: 0.2490 - acc: 0.9136 - val_loss: 0.7331 - val_acc: 0.7751\n",
      "Epoch 83/300\n",
      " - 7s - loss: 0.2502 - acc: 0.9140 - val_loss: 0.7380 - val_acc: 0.7807\n",
      "Epoch 84/300\n",
      " - 6s - loss: 0.2445 - acc: 0.9172 - val_loss: 0.7593 - val_acc: 0.7760\n",
      "Epoch 85/300\n",
      " - 6s - loss: 0.2497 - acc: 0.9122 - val_loss: 0.7732 - val_acc: 0.7726\n",
      "Epoch 86/300\n",
      " - 6s - loss: 0.2430 - acc: 0.9161 - val_loss: 0.7322 - val_acc: 0.7822\n",
      "Epoch 87/300\n",
      " - 6s - loss: 0.2357 - acc: 0.9179 - val_loss: 0.7457 - val_acc: 0.7816\n",
      "Epoch 88/300\n",
      " - 6s - loss: 0.2359 - acc: 0.9188 - val_loss: 0.7324 - val_acc: 0.7783\n",
      "Epoch 89/300\n",
      " - 7s - loss: 0.2361 - acc: 0.9177 - val_loss: 0.7625 - val_acc: 0.7709\n",
      "Epoch 90/300\n",
      " - 6s - loss: 0.2362 - acc: 0.9186 - val_loss: 0.7718 - val_acc: 0.7746\n",
      "Epoch 91/300\n",
      " - 6s - loss: 0.2339 - acc: 0.9198 - val_loss: 0.7330 - val_acc: 0.7807\n",
      "Epoch 92/300\n",
      " - 6s - loss: 0.2309 - acc: 0.9208 - val_loss: 0.7701 - val_acc: 0.7741\n",
      "Epoch 93/300\n",
      " - 7s - loss: 0.2306 - acc: 0.9209 - val_loss: 0.7581 - val_acc: 0.7761\n",
      "Epoch 94/300\n",
      " - 9s - loss: 0.2340 - acc: 0.9193 - val_loss: 0.7570 - val_acc: 0.7773\n",
      "Epoch 95/300\n",
      " - 7s - loss: 0.2317 - acc: 0.9209 - val_loss: 0.7468 - val_acc: 0.7812\n",
      "Epoch 96/300\n",
      " - 7s - loss: 0.2307 - acc: 0.9200 - val_loss: 0.7304 - val_acc: 0.7834\n",
      "Epoch 97/300\n",
      " - 7s - loss: 0.2267 - acc: 0.9218 - val_loss: 0.7862 - val_acc: 0.7705\n",
      "Epoch 98/300\n",
      " - 6s - loss: 0.2232 - acc: 0.9228 - val_loss: 0.7811 - val_acc: 0.7726\n",
      "Epoch 99/300\n",
      " - 7s - loss: 0.2201 - acc: 0.9243 - val_loss: 0.7533 - val_acc: 0.7827\n",
      "Epoch 100/300\n",
      " - 6s - loss: 0.2225 - acc: 0.9223 - val_loss: 0.7571 - val_acc: 0.7787\n",
      "Epoch 101/300\n",
      " - 7s - loss: 0.2230 - acc: 0.9211 - val_loss: 0.7809 - val_acc: 0.7753\n",
      "Epoch 102/300\n",
      " - 7s - loss: 0.2190 - acc: 0.9237 - val_loss: 0.7380 - val_acc: 0.7797\n",
      "Epoch 103/300\n",
      " - 7s - loss: 0.2176 - acc: 0.9245 - val_loss: 0.7504 - val_acc: 0.7831\n",
      "Epoch 104/300\n",
      " - 6s - loss: 0.2146 - acc: 0.9257 - val_loss: 0.7859 - val_acc: 0.7805\n",
      "Epoch 105/300\n",
      " - 7s - loss: 0.2151 - acc: 0.9259 - val_loss: 0.7300 - val_acc: 0.7878\n",
      "Epoch 106/300\n",
      " - 7s - loss: 0.2159 - acc: 0.9260 - val_loss: 0.7551 - val_acc: 0.7829\n",
      "Epoch 107/300\n",
      " - 7s - loss: 0.2150 - acc: 0.9267 - val_loss: 0.7672 - val_acc: 0.7795\n",
      "Epoch 108/300\n",
      " - 7s - loss: 0.2158 - acc: 0.9259 - val_loss: 0.7561 - val_acc: 0.7819\n",
      "Epoch 109/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-4e62d5cee40b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#Adam(lr=0.002)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m350\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#label pre-train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\kk\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])#Adam(lr=0.002)\n",
    "hist=model.fit(x_train, y_train, batch_size=350, epochs=300, verbose=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#test loss, test accuracy print\n",
    "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(\"test loss : \",test_loss,\" test acc : \", test_acc) #정확도 대략 80%\n",
    "\n",
    "#train loss plot\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#train accuracy plot\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['acc', 'val_acc'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
